{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the text to create a dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training dataste by only considering Bart and Homer sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening bart_the_general.txt..\n",
      "\tFound 143 sentences in bart_the_general.txt file\n",
      "Opening bart_the_genius.txt..\n",
      "\tFound 119 sentences in bart_the_genius.txt file\n",
      "Opening donnie_fatso.txt..\n",
      "\tFound 17 sentences in donnie_fatso.txt file\n",
      "Opening there_is_no_disgrace_like_home.txt..\n",
      "\tFound 93 sentences in there_is_no_disgrace_like_home.txt file\n",
      "Opening the_star_of_the_backstage.txt..\n",
      "\tFound 14 sentences in the_star_of_the_backstage.txt file\n",
      "Opening treehouse_of_horror_V.txt..\n",
      "\tFound 66 sentences in treehouse_of_horror_V.txt file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define a list of valid names in lowercase\n",
    "valid_names = ['homer', 'homer simpson', 'homer simpsons', 'bart', 'bart simpson']\n",
    "\n",
    "# Step 2: Loop through each file in the 'simpson/' folder\n",
    "data_list = []\n",
    "folder_path = 'data/simpson/'\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if(not file_name.endswith('.txt')): continue\n",
    "    data_file = []\n",
    "    print(f\"Opening {file_name}..\")\n",
    "    #if(file_name != 'bart_the_general.txt'): continue\n",
    "\n",
    "    #print(f\"We are in\")\n",
    "    with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "        # Step 3: For each file, read its content line by line\n",
    "        for line in file:\n",
    "            # Convert the line to lowercase for comparison\n",
    "            lower_line = line.lower()\n",
    "\n",
    "            #print(lower_line)\n",
    "            # Step 4: Check if a line starts with one of the specific names\n",
    "            for name in valid_names:\n",
    "                if lower_line.startswith(name + \":\"):\n",
    "                    #print(\"FOUND IT\")\n",
    "                    # Extract the actual sentence (without converting to lowercase)\n",
    "                    sentence = line[len(name)+2:].strip()  # +2 to remove the \": \"\n",
    "                    if name in ['homer', 'homer simpson', 'homer simpsons']:\n",
    "                        speaker = 'Homer'\n",
    "                    else:\n",
    "                        speaker = 'Bart'\n",
    "                    data_file.append((speaker, sentence, file_name))\n",
    "                    break\n",
    "    print(f\"\\tFound {len(data_file)} sentences in {file_name} file\")\n",
    "    data_list += data_file\n",
    "\n",
    "# Step 5: Append the data to a dataframe with the specified columns\n",
    "df = pd.DataFrame(data_list, columns=['Name', 'Sentence', 'File'])\n",
    "\n",
    "# Step 6: Save the dataframe as `dataset_homer_bart.csv`\n",
    "df.to_csv('data/simpson/dataset_homer_bart.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
