{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization is a popular technique in recommendation systems, especially for collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrix factorization assumes that any user-song interaction can be explained by latent factors. \n",
    "- For instance, in the context of songs, these factors might represent genres, moods, or other abstract features, but they aren't explicitly labeled.\n",
    "- The matrix factorization methods work best when the user-song matrix is dense. For very sparse matrices, you might need to employ techniques like alternating least squares (ALS) or stochastic gradient descent (SGD) to handle the missing values effectively.\n",
    "- Over time, as more user interactions are gathered, the model may need to be re-trained or updated to reflect new patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps**\n",
    "\n",
    "#### 1. **Prepare the Data**:\n",
    "Start with the user-song matrix where each row represents a user, each column represents a song, and the values represent the user's rating of that song (or interaction strength).\n",
    "#### 2. **Choose the Number of Factors (k)**:\n",
    "Decide on the number of latent factors `k`. These represent abstract features that can explain the patterns in the ratings. A higher `k` will capture more subtle structures but may also overfit. The optimal value of `k` is often determined through cross-validation.\n",
    "#### 3. **Factorize the Matrix**:\n",
    "Use a matrix factorization technique like Singular Value Decomposition (SVD) to decompose the user-song matrix `R` into three matrices: `U`, `Σ`, and `V^T`.\n",
    "\n",
    "- `U` (User matrix): Represents the relationship between users and the latent factors.\n",
    "- `Σ` (Diagonal matrix): Represents the strength of each latent factor.\n",
    "- `V^T` (Song matrix): Represents the relationship between songs and the latent factors.\n",
    "\n",
    "Mathematically, $$ R \\approx U \\times \\Sigma \\times V^T $$\n",
    "\n",
    "#### 4. **Generate Predicted Ratings**:\n",
    "Using the factorized matrices, we can predict a user's rating for a song as follows:\n",
    "$$ \\text{predicted rating} = \\text{row of U for user} \\times \\Sigma \\times \\text{column of } V^T \\text{ for song} $$\n",
    "\n",
    "#### 5. **Recommend Songs**:\n",
    "To recommend songs to a specific user:\n",
    "\n",
    "- Compute the predicted ratings for all songs for that user using the factorized matrices.\n",
    "- Sort the songs based on the predicted ratings.\n",
    "- Recommend the top-N songs that the user hasn't interacted with (or rated) yet.\n",
    "\n",
    "#### 6. **Others**:\n",
    "-To ensure the recommendations are good, split your data into training and testing sets. Train the matrix factorization model on the training set and evaluate its performance on the test set. Common metrics include RMSE (Root Mean Square Error) and MAE (Mean Absolute Error).\n",
    "- Based on the performance on the test set, you might need to:\n",
    "    - Adjust the number of latent factors `k`.\n",
    "    - Use regularization techniques to prevent overfitting if you're using methods that support it (e.g., SVD++ or matrix factorization techniques from libraries like `surprise`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4163\n",
      "RMSE: 1.4163442377854456\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from src.utils import load_dataset\n",
    "\n",
    "# Create user-song matrix\n",
    "dataframe = load_dataset()\n",
    "user_song_matrix = dataframe.pivot_table(index='User_Name', columns='Song', values='Star_Rating', fill_value=0)\n",
    "df = user_song_matrix.stack().reset_index()\n",
    "df.columns = ['User', 'Song', 'Rating']\n",
    "\n",
    "reader = Reader(rating_scale=(df.Rating.min(), df.Rating.max()))  # Define the rating scale based on your dataset\n",
    "data = Dataset.load_from_df(df[['User', 'Song', 'Rating']], reader)\n",
    "\n",
    "# Split data into train and test set\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Use Singular Value Decomposition (SVD) for matrix factorization\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "def get_top_n_recommendations(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\"\"\"\n",
    "    \n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n.setdefault(uid, []).append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the N highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "top_n_recommendations = get_top_n_recommendations(predictions, n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Song292', 2.439305897868699),\n",
       " ('Song253', 1.8549174882774002),\n",
       " ('Song87', 1.7108502215512469),\n",
       " ('Song7', 1.6820684334196407),\n",
       " ('Song67', 1.5834276396147273),\n",
       " ('Song272', 1.5168783496560199),\n",
       " ('Song82', 1.433099071529223),\n",
       " ('Song223', 1.3914276189153707),\n",
       " ('Song146', 1.3502125351920484),\n",
       " ('Song211', 1.320084119557865)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_recommendations['Alice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Problems with Matrix Factorization:\n",
    "\n",
    "1. **Cold Start Problem**: MF struggles with new users or items (songs, in your case) that have no or very few ratings. Because MF is purely collaborative, it can't recommend items to new users or suggest new items to any users until enough data about these new entities accumulates.\n",
    "\n",
    "2. **Sparsity**: User-item matrices are typically very sparse, meaning most users have not rated most items. Even though MF deals relatively well with sparsity compared to other methods, extreme sparsity can still be a challenge.\n",
    "\n",
    "3. **Scalability**: Matrix factorization methods can be computationally expensive, particularly as the size of the user-item matrix grows. This can be mitigated with stochastic gradient descent or other optimization approaches, but it's still a concern for very large datasets.\n",
    "\n",
    "4. **Overfitting**: Especially with deep matrix factorization or when the latent factor number is high, the model can overfit to the training data. Regularization methods and techniques like dropout can help mitigate this.\n",
    "\n",
    "5. **Static Model**: The classic MF does not inherently consider temporal dynamics. User preferences can change over time, and newer models like time-aware matrix factorization attempt to address this, but the basic MF does not.\n",
    "\n",
    "6. **Lack of Interpretability**: Unlike content-based methods, MF lacks interpretability. It's hard to explain why a particular recommendation was made based solely on latent factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE (Root Mean Square Error):\n",
    "\n",
    "The value of RMSE depends on the scale of your ratings, as the values presented above are not normalised. If your song ratings are on a scale from 1 to 5, then an RMSE of 0.5 means that the model's predictions are off by half a rating point on average. In the context of a 1-5 rating scale:\n",
    "\n",
    "- An **RMSE of 0.5** or lower could be considered good.\n",
    "- An **RMSE of 1.0** would mean that you're off by a full rating point on average, which might be acceptable but not ideal.\n",
    "- An **RMSE higher than 1.0** could be problematic.\n",
    "\n",
    "However, it's crucial to compare RMSE to some baseline (like a naive recommender) and possibly other metrics, depending on your application. Also, low RMSE doesn't always mean that users will be satisfied with the recommendations. For instance, the model might provide accurate but obvious and uninteresting recommendations. That's why it's often helpful to combine RMSE with other evaluation metrics and real-world user testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
